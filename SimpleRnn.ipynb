{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleRnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhduCV3+mz4DltUcdhzmsH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohitduklan/Deep-Learning/blob/master/SimpleRnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0KUrEHwOHdw"
      },
      "source": [
        "!pip install tensorflow==2.2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_BCnDGNL5a2"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import re"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcEsogNEL9up"
      },
      "source": [
        "# Input\n",
        "article = '''The list of Odonata species of Slovenia includes 72 species of dragonflies and damselflies (Slovene: kačji pastirji) for which reliable records exist from the present-day territory of Slovenia, including one that has not been seen since the 1960s and is presumed to have been extirpated (locally extinct), but could have simply been overlooked. The list is based on two reference works: Atlas of the Dragonflies (Odonata) of Slovenia,[2] a joint publication of the Slovene Odonatological Society and the Slovene Centre for Cartography of Fauna and Flora from 1997, and the newer Atlas of the European dragonflies and damselflies (2015), supported by other, more recent publications in which new species described after 1997 were documented. Odonata species from the territory of present-day Slovenia were systematically studied by the naturalists Johann Weikhard von Valvasor and Giovanni Antonio Scopoli as early as the 17th and 18th centuries; however, the first systematic compendium was only published in the 1960s by the Slovene zoologist Boštjan Kiauta [sl].[1] The distribution of Odonata in Slovenia is now fairly well known by international standards, with Slovenia having been one of the first European countries for which a full account of faunistic data (an \"atlas\") was published. The number of species (72) represents almost exactly half of the European species (143) and is comparable with the number of species of Germany (81) and Spain (80), both much larger countries.[3] Slovenian odonate fauna is therefore considered highly diverse and is attributed to the country's position on the junction of several ecoregions where many species reach the border of their distribution.'''"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvilGdmKMeut"
      },
      "source": [
        "# Preprocessing\n",
        "article = article.lower() # Lower\n",
        "article = re.sub(\"[^a-z .']+\", \" \", article) # Removing special characters\n",
        "article = re.sub(\"[^a-z .]+\", \"\", article).split() # Spliting word"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJNQFV0XMxe-"
      },
      "source": [
        "# Initializing word to id and id to word dictionary\n",
        "vocab = list(set(article))\n",
        "vocab_size = list(set(article))\n",
        "word2id = {v: w for w, v in enumerate(vocab)}\n",
        "id2word = {w: v for w, v in enumerate(vocab)}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJdy3vL8M2d2",
        "outputId": "12e5dc41-3f98-4915-decd-6cbf0109034c"
      },
      "source": [
        "# Vectorizing text and saving in tf dataset\n",
        "SEQUENCE_LENGTH = 5\n",
        "BATCH_SIZE = 8\n",
        "BUFFER_SIZE = 10000\n",
        "examples_per_epoch = len(article)//(SEQUENCE_LENGTH+1)\n",
        "\n",
        "article_vector = [word2id[x] for x in article]\n",
        "dataset = tf.data.Dataset.from_tensor_slices(article_vector)\n",
        "dataset = dataset.batch(SEQUENCE_LENGTH+1, drop_remainder=True)\n",
        "dataset = dataset.map(lambda x: [x[:-1], x[1:]])\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((8, 5), (8, 5)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee6T5ooDl4C4"
      },
      "source": [
        "# Building model\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super().__init__(self)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(\n",
        "            rnn_units, \n",
        "            return_sequences=True,\n",
        "            return_state=True\n",
        "        )\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = inputs\n",
        "        x = self.embedding(x, training=training)\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(x)\n",
        "        x, states = self.gru(x, initial_state=states, training=training)\n",
        "        x = self.dense(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj1hABd-mSER"
      },
      "source": [
        "# Model parameters\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = 'adam'\n",
        "model = MyModel(vocab_size, embedding_dim, rnn_units)\n",
        "model.compile(optimizer=optimizer, loss=loss)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMNc3NV6SLOq",
        "outputId": "6540794a-b1e1-4e68-fb7f-98d3f32cb0f4"
      },
      "source": [
        "history = model.fit_generator(dataset, epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f35dee7cb00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f35dee7cb00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 162ms/step - loss: 4.9726\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 4.8784\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 1s 158ms/step - loss: 4.6701\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 1s 159ms/step - loss: 4.5051\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 4.1682\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 4.0942\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 3.8393\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 3.5601\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 3.2540\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 2.8043\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 2.4274\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 2.1217\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 1s 159ms/step - loss: 1.7640\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 1.4959\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.2491\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 1.1188\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 0.8853\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 0.8171\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 0.7229\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 0.6369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0ci-JC_S2rs"
      },
      "source": [
        "p = model.predict(article_vector[8:16])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT0OvqWQUMBH",
        "outputId": "48c29ccf-d0be-4c0c-c55d-179bfc6496f5"
      },
      "source": [
        "[id2word[np.argmax(i[0])] for i in p]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['of', 'the', 'and', 'damselflies', 'slovene', 'zoologist', 'ji', 'list']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    }
  ]
}