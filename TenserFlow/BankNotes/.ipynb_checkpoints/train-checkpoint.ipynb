{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df = pd.read_csv(\"BankNote.csv\")\n",
    "    Xdata = df[df.columns[0:4]].values\n",
    "    Ydata = pd.get_dummies(df[df.columns[4]])\n",
    "    return(Xdata, Ydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffle the dataset to mix up the rows. Convert the dataset into train and test part and INITIALIZING VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_X, All_y = read_dataset()\n",
    "All_X, All_y = shuffle(All_X, All_y, random_state=1)\n",
    "train_X, test_X, train_y, test_y = train_test_split(All_X, All_y, test_size=20, random_state=415)\n",
    "learning_rate = 1.0\n",
    "training_epochs = 501\n",
    "n_features = X.shape[1]\n",
    "n_class = y.shape[1]\n",
    "n_hidden_1 = 5\n",
    "n_hidden_2 = 4\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_features])\n",
    "y_ = tf.placeholder(tf.float32, [None, n_class])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initializing WEIGHTS & BIASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights = {\n",
    "    'H1' : tf.Variable(tf.truncated_normal([n_features, n_hidden_1])),\n",
    "    'H2' : tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'y_' : tf.Variable(tf.truncated_normal([n_hidden_2, n_class]))\n",
    "}\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2' : tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'y_' : tf.Variable(tf.truncated_normal([n_class]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propogation(X, Weights, biases):\n",
    "    Layer1 = tf.nn.relu(tf.add(tf.matmul(X, Weights['H1']), biases['b1']))\n",
    "    Layer2 = tf.nn.relu(tf.add(tf.matmul(Layer1, Weights['H2']), biases['b2']))\n",
    "    y_ = tf.nn.sigmoid(tf.add(tf.matmul(Layer2, Weights['y_']), biases['y_']))\n",
    "    return y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### running global initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0.5940622\n",
      "100   0.31607425\n",
      "200   0.3144538\n",
      "300   0.31401515\n",
      "400   0.31380716\n",
      "500   0.3136865\n"
     ]
    }
   ],
   "source": [
    "y_ = forward_propogation(x, Weights, biases)\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(optimizer, feed_dict={x:train_X, y:train_y})\n",
    "        cost = sess.run(cost_function, feed_dict={x:train_X, y:train_y})\n",
    "        if(epoch%100 == 0):\n",
    "            print(epoch,\" \",cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
